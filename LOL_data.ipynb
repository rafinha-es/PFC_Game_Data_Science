{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafinha-es/PFC_Game_Data_Science/blob/main/LOL_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTANDO DADOS DO DRIVE E BIBLIOTECAS (Compilar por primeiro)"
      ],
      "metadata": {
        "id": "NGHhLYjnaiC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.svm import SVC\n"
      ],
      "metadata": {
        "id": "ArFphiwPwE6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COLETA DE DADOS VIA API - NÃO COMPILAR NOVAMENTE!"
      ],
      "metadata": {
        "id": "mKYXAG7uavPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdRaVHMvueN7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Substitua por sua própria chave da API\n",
        "API_KEY = 'RGAPI-ec9a1949-8fe0-485f-841f-e160f2a9a185'\n",
        "REGION = 'br1'  # Região para o Brasil (pode ser 'na1' para Norte-América, etc.)\n",
        "\n",
        "def get_summoner_id(gameName, tagLine):\n",
        "    url = f'https://americas.api.riotgames.com/riot/account/v1/accounts/by-riot-id/{gameName}/{tagLine}'\n",
        "    headers = {'X-Riot-Token': API_KEY}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()['puuid']\n",
        "    else:\n",
        "        print(f'Error fetching summoner ID: {response.status_code}')\n",
        "        return None\n",
        "\n",
        "def get_matchlist(puuid):\n",
        "    url = f'https://americas.api.riotgames.com/lol/match/v5/matches/by-puuid/{puuid}/ids'\n",
        "    headers = {'X-Riot-Token': API_KEY}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f'Error fetching match list: {response.status_code}')\n",
        "        return None\n",
        "\n",
        "def get_match_data(match_id):\n",
        "    url = f'https://americas.api.riotgames.com/lol/match/v5/matches/{match_id}'\n",
        "    headers = {'X-Riot-Token': API_KEY}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f'Error fetching match data: {response.status_code}')\n",
        "        return None\n",
        "\n",
        "def get_match_timeline(match_id):\n",
        "    url = f'https://americas.api.riotgames.com/lol/match/v5/matches/{match_id}/timeline'\n",
        "    headers = {'X-Riot-Token': API_KEY}\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f'Error fetching match timeline: {response.status_code}')\n",
        "        return None\n",
        "\n",
        "def create_dataframe(match_data_list, match_timeline_list):\n",
        "    rows = []\n",
        "\n",
        "    for match_data, match_timeline in zip(match_data_list, match_timeline_list):\n",
        "        #print('Processing match:', match_data['info']['gameId'])\n",
        "\n",
        "        first_kill_time = float('inf')  # Inicializa com um valor muito alto\n",
        "        first_kill_team = None  # Ainda não sabemos quem fez a primeira kill\n",
        "\n",
        "        # Check if 'frames' key exists in match_timeline['info']\n",
        "        if 'frames' in match_timeline['info']:\n",
        "            for frame in match_timeline['info']['frames']:\n",
        "                for event in frame.get('events', []):\n",
        "                    if event['type'] == 'CHAMPION_KILL':  # Evento de kill encontrado\n",
        "                        killer_id = event.get('killerId', 0)\n",
        "                        victim_id = event.get('victimId', 0)\n",
        "\n",
        "                        # Verifica se tanto o assassino quanto a vítima são jogadores válidos\n",
        "                        if killer_id != 0 and victim_id != 0:\n",
        "                            event_time = event['timestamp']\n",
        "\n",
        "                            # Se for a primeira kill feita por um player contra outro player\n",
        "                            if event_time < first_kill_time:\n",
        "                                first_kill_time = event_time\n",
        "\n",
        "                                # Descobre qual time fez a first kill\n",
        "                                for participant in match_data['info']['participants']:\n",
        "                                    if participant['participantId'] == killer_id:\n",
        "                                        first_kill_team = participant['teamId']  # Guarda o time numérico (100 ou 200)\n",
        "                                        #print(f\"A first kill foi feita pelo time {'Blue' if first_kill_team == 100 else 'Red'}\")\n",
        "                                        break  # Já encontramos, podemos parar a busca\n",
        "        else:\n",
        "            print(\"No 'frames' key found in match_timeline['info']\")\n",
        "\n",
        "        for participant in match_data['info']['participants']:\n",
        "            team_color = 'Blue' if participant['teamId'] == 100 else 'Red'\n",
        "            row = {\n",
        "                'Game ID': match_data['info']['gameId'],\n",
        "                'Duration': match_data['info']['gameDuration'],\n",
        "                'Game Mode': match_data['info']['gameMode'],\n",
        "                'Summoner Name': participant['summonerName'],\n",
        "                'Champion': participant['championName'],\n",
        "                'Kills': participant['kills'],\n",
        "                'Deaths': participant['deaths'],\n",
        "                'Assists': participant['assists'],\n",
        "                'Team ID': participant['teamId'],\n",
        "                'Team': team_color,\n",
        "                'Team FK': first_kill_team is not None and first_kill_team == participant['teamId'],\n",
        "                'Team Win': \"Win\" if participant['win'] == True else \"Lose\",\n",
        "            }\n",
        "            rows.append(row)\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    full_tag = \"dyNNKaz #1010\" #Riot ID do player\n",
        "\n",
        "    gameName, tagLine = full_tag.split(\" #\")\n",
        "    summoner_puuid = get_summoner_id(gameName, tagLine)\n",
        "\n",
        "    if not summoner_puuid:\n",
        "        return\n",
        "\n",
        "    match_ids = get_matchlist(summoner_puuid)\n",
        "\n",
        "    if not match_ids:\n",
        "        return\n",
        "\n",
        "    match_data_list = []\n",
        "    match_timeline_list = []\n",
        "\n",
        "    # Obtemos os dados de até 20 partidas para demonstração\n",
        "    for match_id in match_ids[:20]:\n",
        "        match_data = get_match_data(match_id)\n",
        "        match_timeline = get_match_timeline(match_id)\n",
        "\n",
        "        if match_data and match_timeline:\n",
        "            match_data_list.append(match_data)\n",
        "            match_timeline_list.append(match_timeline)\n",
        "\n",
        "    # Criar o DataFrame\n",
        "    df = create_dataframe(match_data_list, match_timeline_list)\n",
        "\n",
        "    # Salvar o DataFrame em um arquivo CSV\n",
        "    df.to_csv(f'/content/gameplay_data_players/gameplay_data_{gameName}{tagLine}.csv', index=False)\n",
        "    print(f'Dados salvos em gameplay_data_{gameName}{tagLine}.csv')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTE DA BASE POR JOGADOR"
      ],
      "metadata": {
        "id": "c62qreUia_lY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Databases/root/gameplay_data_tinownsBR2.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df.head(20)"
      ],
      "metadata": {
        "id": "L8xaKFr_XpCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTE DAS BASES DE DADOS UNIFICADAS"
      ],
      "metadata": {
        "id": "xxDkyhCLbPvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Databases/updated_ALL_gameplay_data.csv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    num_linhas = sum(1 for _ in reader) - 1  # Subtrai 1 para ignorar o cabeçalho\n",
        "print(f\"O arquivo tem {num_linhas} linhas de dados.\")"
      ],
      "metadata": {
        "id": "sjCIsfMk8s04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the CSV files\n",
        "csv_directory = '/content/gameplay_data_players'\n",
        "\n",
        "# Define the output file name\n",
        "output_file = 'ALL_gameplay_data.csv'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for filename in os.listdir(csv_directory):\n",
        "    if filename.endswith('.csv'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(csv_directory, filename)\n",
        "\n",
        "        # Read the CSV file into a DataFrame\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        # Append the DataFrame to the list\n",
        "        dataframes.append(df)\n",
        "\n",
        "# Concatenate all DataFrames into a single DataFrame\n",
        "unified_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Write the unified DataFrame to a new CSV file (header is written only once)\n",
        "unified_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"All CSV files have been unified into {output_file}\")"
      ],
      "metadata": {
        "id": "wPij0ZuF9n3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/ALL_gameplay_data.csv')\n",
        "\n",
        "# Calculate KD with division by zero handling\n",
        "df['KD'] = np.where(df['Deaths'] == 0, df['Kills'], df['Kills'] / df['Deaths'])\n",
        "\n",
        "# Calculate KDA with division by zero handling\n",
        "df['KDA'] = np.where(df['Deaths'] == 0, (df['Kills'] + df['Assists']), (df['Kills'] + df['Assists']) / df['Deaths'])\n",
        "\n",
        "# Calculate DF with division by zero handling\n",
        "df['DF'] = (3*(df['Kills']) + 1*(df['Assists']) - (3*df['Deaths']))\n",
        "\n",
        "# Calculate KDA with division by zero handling\n",
        "df['DR'] = np.where(df['Deaths'] == 0, (2*(df['Kills']) + 1*(df['Assists'])), (2*(df['Kills']) + 1*(df['Assists']))/(3*df['Deaths']))\n",
        "\n",
        "\n",
        "#print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "output_path = '/content/updated_ALL_gameplay_data.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Updated DataFrame saved to {output_path}\")"
      ],
      "metadata": {
        "id": "sMR-B7AuDRXO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Databases/updated_ALL_gameplay_data.csv')\n",
        "df.drop(columns=[\"Game ID\", \"Team ID\"]).describe()"
      ],
      "metadata": {
        "id": "1LMLnyD_Lhdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Databases/updated_ALL_gameplay_data.csv')\n",
        "df_byTeam = df.groupby([\"Game ID\", \"Team\"]).agg({ #As colunas a serem filtradas vão como argumentos no df.groupby\n",
        "    \"Duration\": \"first\",\n",
        "    \"Kills\": \"mean\",       # Somar kills do time\n",
        "    \"Deaths\": \"mean\",\n",
        "    \"Assists\": \"mean\",\n",
        "    \"Team FK\": \"first\",   # Manter primeiro valor (é igual para o time todo)\n",
        "    \"Team Win\": \"first\"   # Manter primeiro valor (é igual para o time todo)\n",
        "}).reset_index()\n",
        "\n",
        "# Exibir resultado\n",
        "print(df_byTeam)\n",
        "df_byTeam.describe()"
      ],
      "metadata": {
        "id": "vMCfFnRhT5xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Célula para gravar .csv filtrado por time/partida"
      ],
      "metadata": {
        "id": "PKb1wzQaNnwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/MyDrive/Databases/byTeam_gameplay_data.csv'\n",
        "df_byTeam.to_csv(output_path, index=False)\n",
        "print(f\"Updated DataFrame saved to {output_path}\")"
      ],
      "metadata": {
        "id": "YEXXwFRINv8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Databases/updated_ALL_gameplay_data.csv')\n",
        "df_byMatch = df.groupby([\"Game ID\"]).agg({ #As colunas a serem filtradas vão como argumentos no df.groupby\n",
        "    \"Duration\": \"first\",\n",
        "    \"Kills\": \"sum\",       # Somar kills do time\n",
        "    \"Deaths\": \"sum\",\n",
        "    \"Assists\": \"sum\",\n",
        "\n",
        "}).reset_index()\n",
        "\n",
        "# Exibir resultado\n",
        "print(df_byMatch)\n",
        "df_byMatch.describe()"
      ],
      "metadata": {
        "id": "8jIWBbLsYVQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Times vencedores"
      ],
      "metadata": {
        "id": "G_ckmzVFKX7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar apenas os times vencedores\n",
        "df_winners = df_byTeam[df_byTeam[\"Team Win\"] == \"Win\"]\n",
        "\n",
        "# Exibir resultado\n",
        "print(df_winners)\n",
        "df_winners.describe()"
      ],
      "metadata": {
        "id": "iZpzfOP4KaGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Times perdedores"
      ],
      "metadata": {
        "id": "POgrlXI0KgJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar apenas os times vencedores\n",
        "df_losers = df_byTeam[df_byTeam[\"Team Win\"] == \"Lose\"]\n",
        "\n",
        "# Exibir resultado\n",
        "print(df_losers)\n",
        "df_losers.describe()"
      ],
      "metadata": {
        "id": "uwI-0afVKiXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZAÇÃO COM GRÁFICOS"
      ],
      "metadata": {
        "id": "5hLeXiFiaoz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_players = pd.read_csv(\"/content/drive/MyDrive/Databases/updated_ALL_gameplay_data.csv\")\n",
        "df_teams = pd.read_csv(\"/content/drive/MyDrive/Databases/byTeam_gameplay_data.csv\")\n",
        "\n",
        "print(df_teams)"
      ],
      "metadata": {
        "id": "qbrZGKdXGRVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar base já agregada por time\n",
        "df_teams = pd.read_csv(\"/content/drive/MyDrive/Databases/byTeam_gameplay_data.csv\")\n",
        "\n",
        "# Pegar apenas o time que fez a First Kill (1 por partida)\n",
        "fk_true = df_teams[df_teams[\"Team FK\"] == 1]\n",
        "\n",
        "# Verificar se o time que fez a First Kill venceu ou perdeu\n",
        "fk_vs_win = fk_true[\"Team Win\"].value_counts()\n",
        "print(fk_vs_win)\n",
        "\n",
        "\n",
        "\n",
        "# Criar o gráfico de barras\n",
        "plt.figure(figsize=(6, 3))\n",
        "fk_vs_win.plot(kind='barh', color=[\"#0dd41a\", \"#bc2d2d\"])\n",
        "#plt.title('Vitórias quando Time consegue First Kill')\n",
        "plt.ylabel('Resultado')\n",
        "plt.xlabel('Número de Partidas')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q1fLPv-ravjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TESTE QUI-QUADRADO"
      ],
      "metadata": {
        "id": "yYP5kkz_cLIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar sua base\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Databases/byTeam_gameplay_data.csv\")\n",
        "\n",
        "# Criar a tabela de contingência entre Team FK e Team Win\n",
        "contingencia = pd.crosstab(df[\"Team FK\"], df[\"Team Win\"])\n",
        "print(\"Tabela de Contingência:\")\n",
        "print(contingencia)\n",
        "\n",
        "# Aplicar o teste do qui-quadrado\n",
        "chi2, p, dof, expected = chi2_contingency(contingencia)\n",
        "\n",
        "print(f\"\\nResultado do teste do Qui-quadrado:\")\n",
        "print(f\"Estatística Qui²: {chi2:.4f}\")\n",
        "print(f\"Valor-p: {p:.4f}\")\n",
        "print(f\"Graus de liberdade: {dof}\")\n",
        "print(\"Tabela Esperada:\")\n",
        "print(expected)\n",
        "\n",
        "# Calcular V de Cramér\n",
        "n = contingencia.sum().sum()  # Total de observações\n",
        "phi2 = chi2 / n\n",
        "r, k = contingencia.shape\n",
        "v_cramer = np.sqrt(phi2 / min(k - 1, r - 1))\n",
        "\n",
        "print(f\"\\nV de Cramér: {v_cramer:.4f}\")\n"
      ],
      "metadata": {
        "id": "mruXH62ec0QL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar sua base\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Databases/byTeam_gameplay_data.csv\")\n",
        "\n",
        "# Criar a tabela de contingência entre Team FK e Team Win\n",
        "contingencia = pd.crosstab(df[\"Team FK\"], df[\"Team Win\"])\n",
        "print(\"Tabela de Contingência:\")\n",
        "print(contingencia)\n",
        "\n",
        "# Aplicar o teste do qui-quadrado\n",
        "chi2, p, dof, expected = chi2_contingency(contingencia)\n",
        "\n",
        "print(f\"\\nResultado do teste do Qui-quadrado:\")\n",
        "print(f\"Estatística Qui²: {chi2:.4f}\")\n",
        "print(f\"Valor-p: {p:.4f}\")\n",
        "print(f\"Graus de liberdade: {dof}\")\n",
        "print(\"Tabela Esperada:\")\n",
        "print(expected)\n",
        "\n",
        "# Calcular V de Cramér\n",
        "n = contingencia.sum().sum()  # Total de observações\n",
        "phi2 = chi2 / n\n",
        "r, k = contingencia.shape\n",
        "v_cramer = np.sqrt(phi2 / min(k - 1, r - 1))\n",
        "\n",
        "print(f\"\\nV de Cramér: {v_cramer:.4f}\")\n"
      ],
      "metadata": {
        "id": "9-EcvFM9aBwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plot de Kills vs Deaths por time\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='Kills', y='Deaths', hue='Team', style='Team Win', data=df_teams)\n",
        "plt.title('Kills vs Deaths por Time')\n",
        "plt.xlabel('Kills')\n",
        "plt.ylabel('Deaths')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qnUpW9JXO-eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "sns.histplot(df_byTeam[\"Kills\"], bins=20, kde=True, color=\"blue\")\n",
        "\n",
        "plt.title(\"Distribuição de Kills por Time\")\n",
        "plt.xlabel(\"Kills\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gtYqDK9uRvoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_player = pd.read_csv(\"/content/drive/MyDrive/Databases/updated_ALL_gameplay_data.csv\")\n",
        "df_player[\"Team Win\"] = df_player[\"Team Win\"].map({\"Win\": 1, \"Lose\": 0})\n",
        "# Converter True para 1 e False para 0 em 'Team FK'\n",
        "df_player[\"Team FK\"] = df_player[\"Team FK\"].map({True: 1, False: 0})\n",
        "\n",
        "output_path = '/content/drive/MyDrive/Databases/win_lose_filtered.csv'\n",
        "df_player.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Updated DataFrame saved to {output_path}\")\n"
      ],
      "metadata": {
        "id": "DLnZbagqXwbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DADOS SEPARADOS POR PLAYERS"
      ],
      "metadata": {
        "id": "AoDryaxPJLBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando por nome exato do jogador\n",
        "df_player = pd.read_csv(\"/content/drive/MyDrive/Databases/updated_ALL_gameplay_data.csv\") #pegar de updatedALL, se pegar das root nao tem as outras informações\n",
        "\n",
        "df_player[\"Team Win\"] = df_player[\"Team Win\"].map({\"Win\": 1, \"Lose\": 0})\n",
        "# Converter True para 1 e False para 0 em 'Team FK'\n",
        "df_player[\"Team FK\"] = df_player[\"Team FK\"].map({True: 1, False: 0})\n",
        "\n",
        "summonerName = \"ROBOCA DE SACOLA\" #Trocar o nome do player\n",
        "filtered_df = df_player[df_player[\"Summoner Name\"].str.strip().str.lower() == summonerName.lower()]\n",
        "\n",
        "\n",
        "print(filtered_df)\n",
        "filtered_df.describe()\n"
      ],
      "metadata": {
        "id": "FTDqHWpSJQbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. BOXPLOT\n",
        "  \n",
        "  1.1. Varios gráficos de uma vez"
      ],
      "metadata": {
        "id": "nEUFH-JgYeaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "melted_df = filtered_df[[\"Kills\", \"Deaths\", \"Assists\"]].melt(var_name=\"Estatística\", value_name=\"Valor\") #TROCAR AQUI AS VARIÁVEIS \"KD\", \"KDA\", \"DR\" ou\n",
        "                                                                                          #\"Kills\", \"Deaths\", \"Assists\"\n",
        "# Criar o boxplot\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.boxplot(data=melted_df, x=\"Estatística\", y=\"Valor\", color=\"#0ff000\")\n",
        "plt.title(f\"Kills, Deaths e Assists - {summonerName}\") #TROCAR AQUI AS VARIÁVEIS     KD, KDA e DR    ou    Kills, Deaths e Assists\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oR13vUVtU9z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.2. Grafico DF"
      ],
      "metadata": {
        "id": "g5onf5o13DVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stat = \"DF\"  # Métrica única que você quer analisar\n",
        "\n",
        "# Criar o boxplot para apenas uma estatística\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.boxplot(data=filtered_df, y=stat, color=\"#0ff000\")  # Cor personalizada\n",
        "\n",
        "plt.title(f\"{stat} - {summonerName}\")\n",
        "plt.ylabel(\"Valor\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JECkIRQ72vi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. HISTOGRAMA\n",
        "\n",
        "2.1. Varios graficos de uma vez"
      ],
      "metadata": {
        "id": "ov1BL52AYoS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar subplots para as variáveis separadamente\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
        "\n",
        "# Cores personalizadas\n",
        "\n",
        "cores = {\n",
        "    \"Kills\": \"#00C49A\",     # Verde água escuro\n",
        "    \"Deaths\": \"#FF5733\",    # Laranja avermelhado\n",
        "    \"Assists\": \"#5DA5DA\"    # Azul claro\n",
        "}\n",
        "\n",
        "# Criar histogramas separados para cada métrica\n",
        "for ax, stat in zip(axes, [\"Kills\", \"Deaths\", \"Assists\"]):  #TROCAR AQUI AS VARIÁVEIS \"KD\", \"KDA\", \"DR\" ou\n",
        "    sns.histplot(                               #\"Kills\", \"Deaths\", \"Assists\"\n",
        "        data=filtered_df,\n",
        "        x=stat,\n",
        "        bins=10,\n",
        "        kde=True,\n",
        "        stat=\"density\",\n",
        "        color=cores[stat],\n",
        "        ax=ax\n",
        "    )\n",
        "    ax.set_title(f\"Distribuição de {stat}\")\n",
        "    ax.set_xlabel(\"Quantidade\")\n",
        "    ax.set_ylabel(\"Densidade\")\n",
        "    ax.grid(True)\n",
        "\n",
        "# Título geral do gráfico\n",
        "plt.suptitle(f\"Distribuição de Estatísticas - {summonerName}\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KH_luRBkZ7QU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2. GRÁFICO DF"
      ],
      "metadata": {
        "id": "QAFAza3VgQ-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Estatística que você quer plotar (escolha uma das que você usaria antes)\n",
        "stat = \"DF\"\n",
        "\n",
        "# Criar histograma para uma única métrica\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(\n",
        "    data=filtered_df,\n",
        "    x=stat,\n",
        "    bins=10,\n",
        "    kde=True,\n",
        "    stat=\"density\",\n",
        ")\n",
        "\n",
        "plt.title(f\"Distribuição de {stat}\")\n",
        "plt.xlabel(\"Quantidade\")\n",
        "plt.ylabel(\"Densidade\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Título geral (pode remover se for só um gráfico mesmo)\n",
        "plt.suptitle(f\"Distribuição de Estatísticas - {summonerName}\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Dp-SCSYRgVmk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MATRIZES DE CORRELAÇÃO"
      ],
      "metadata": {
        "id": "jK0Sbz3bgW7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\")\n",
        "player_filter = [\"roboca de sacola\", \"tinowns01\", \"pain dynkas\", \"titan\"]\n",
        "\n",
        "# Filtrar os nomes ignorando espaços e caixa alta\n",
        "df_filtrado = df[df[\"Summoner Name\"].str.strip().str.lower().isin(player_filter)]\n",
        "colunas_analise = [\"Kills\", \"Deaths\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\",\"Team FK\",\"Team Win\"]\n",
        "correlacao = df_filtrado[colunas_analise].corr()\n"
      ],
      "metadata": {
        "id": "hnHFg-l2fqi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VISUALIZAÇÃO COM HEATMAP\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlacao, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Matriz de Correlação - 4 Jogadores\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uJBFJADugbzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODOS OS PLAYERS"
      ],
      "metadata": {
        "id": "OYg_DfR_mO64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = df\n",
        "colunas_analise = [\"Kills\", \"Deaths\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\",\"Team FK\",\"Team Win\"]\n",
        "correlacao_all = df_all[colunas_analise].corr()"
      ],
      "metadata": {
        "id": "uEu2k9OKjE9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VISUALIZAÇÃO COM HEATMAP\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlacao_all, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Matriz de Correlação - Todos os players\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kYhLHYyljk9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MACHINE LEARNING - RANDOM FOREST"
      ],
      "metadata": {
        "id": "7E-j8lSwo-Yl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REGRESSION"
      ],
      "metadata": {
        "id": "KZ9cfV0HAsHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIMPANDO OUTLIERS"
      ],
      "metadata": {
        "id": "dIBGF9e--r6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Carregar os datasets\n",
        "df_principal = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\")   # Seu banco de dados completo\n",
        "df_outliers = pd.read_csv(\"/content/drive/MyDrive/Databases/Outliers.csv\")       # Seu arquivo só com os outliers\n",
        "\n",
        "\n",
        "# Juntar \"Game ID\" + \"Summoner Name\" em uma única chave para facilitar a comparação\n",
        "df_principal[\"chave\"] = df_principal[\"Game ID\"].astype(str) + \"-\" + df_principal[\"Summoner Name\"].str.strip()\n",
        "df_outliers[\"chave\"] = df_outliers[\"Game ID\"].astype(str) + \"-\" + df_outliers[\"Summoner Name\"].str.strip()\n",
        "\n",
        "# Agora manter apenas as linhas que NÃO estão na lista de outliers\n",
        "df_sem_outliers = df_principal[~df_principal[\"chave\"].isin(df_outliers[\"chave\"])]\n",
        "\n",
        "# Remover a coluna auxiliar 'chave'\n",
        "df_sem_outliers = df_sem_outliers.drop(columns=[\"chave\"])\n",
        "df_sem_outliers = df_sem_outliers.reset_index(drop=True)\n",
        "\n",
        "# Visualizar o resultado\n",
        "print(df_sem_outliers)\n",
        "\n"
      ],
      "metadata": {
        "id": "STRa--ff-uFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o arquivo\n",
        "#df = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\") #COM OUTLIERS\n",
        "df = df_sem_outliers #SEM OUTLIERS\n",
        "\n",
        "# Definir a lista de variáveis de interesse\n",
        "variaveis = [\"Kills\", \"Deaths\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\"]\n",
        "\n",
        "# Preparar a função para rodar regressão para cada variável\n",
        "resultados = []\n",
        "\n",
        "for alvo in variaveis:\n",
        "    # Definir y como a variável alvo\n",
        "    y = df[alvo]\n",
        "\n",
        "    # Definir X como todas as outras variáveis, exceto o alvo\n",
        "    X = df[[v for v in variaveis if v != alvo]]\n",
        "\n",
        "    # Criar o modelo\n",
        "    modelo = RandomForestRegressor(random_state=42)\n",
        "\n",
        "    # Definir o KFold (5 partes)\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_test)\n",
        "\n",
        "        mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
        "        rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "    # Guardar os resultados\n",
        "    resultados.append({\n",
        "        \"Variável\": alvo,\n",
        "        \"MAE Médio\": np.mean(mae_scores),\n",
        "        \"RMSE Médio\": np.mean(rmse_scores)\n",
        "    })\n",
        "\n",
        "# Criar DataFrame de resultados\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "\n",
        "# Visualizar\n",
        "print(df_resultados)\n"
      ],
      "metadata": {
        "id": "URuVK3StpFJX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFIER"
      ],
      "metadata": {
        "id": "bWAbtyWVDyig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "#df = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\")\n",
        "df = df_sem_outliers #SEM OUTLIERS\n",
        "\n",
        "# Definir variáveis\n",
        "X = df[[\"Kills\", \"Deaths\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\"]]  # Atributos de entrada\n",
        "y = df[\"Team Win\"]  # Variável de saída (0 ou 1)\n",
        "\n",
        "# 4. Criar o modelo\n",
        "modelo = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Definir KFold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Avaliar via cross-validation\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Mostrar resultados médios\n",
        "print(f\"Acurácia média: {np.mean(accuracy_scores):.4f}\")\n",
        "print(f\"Precision média: {np.mean(precision_scores):.4f}\")\n",
        "print(f\"Recall média: {np.mean(recall_scores):.4f}\")\n",
        "print(f\"F1-Score média: {np.mean(f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "1zwapLZeD1zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "d1cAwSXgZNDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REGRESSOR\n"
      ],
      "metadata": {
        "id": "pLonfh20dte2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\")\n",
        "#df = df_sem_outliers #SEM OUTLIERS\n",
        "\n",
        "y = df[\"Assists\"]  # variável alvo\n",
        "X = df[[\"Kills\", \"Deaths\", \"KD\", \"KDA\", \"DF\", \"DR\"]]  # entrada (sem 'Kills')\n",
        "\n",
        "# Definir modelo\n",
        "modelo = XGBRegressor(random_state=42)\n",
        "\n",
        "# K-Fold Cross Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "mae_scores = []\n",
        "rmse_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
        "    rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
        "\n",
        "# Resultados finais\n",
        "print(f\"MAE médio: {np.mean(mae_scores):.4f}\")\n",
        "print(f\"RMSE médio: {np.mean(rmse_scores):.4f}\")"
      ],
      "metadata": {
        "id": "JLbzC_JAZZd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLASSIFIER\n"
      ],
      "metadata": {
        "id": "I6YxYAEYKVcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\")\n",
        "#df = df_sem_outliers #SEM OUTLIERS\n",
        "\n",
        "# Definir X e y\n",
        "X = df[[\"Kills\", \"Deaths\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\"]]\n",
        "y = df[\"Team Win\"]\n",
        "\n",
        "# Criar o modelo\n",
        "modelo = XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "\n",
        "# Validar com K-Fold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Resultados finais\n",
        "resultados = {\n",
        "    \"Métrica\": [\"Acurácia\", \"Precision\", \"Recall\", \"F1-Score\"],\n",
        "    \"Valor Médio\": [\n",
        "        np.mean(accuracy_scores),\n",
        "        np.mean(precision_scores),\n",
        "        np.mean(recall_scores),\n",
        "        np.mean(f1_scores)\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(df_resultados)"
      ],
      "metadata": {
        "id": "INmhoeGSKVcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CxB5B_4DSB5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVR"
      ],
      "metadata": {
        "id": "LOHBDvlNSFVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\")\n",
        "\n",
        "# Variáveis de entrada por alvo\n",
        "entradas_por_alvo = {\n",
        "    \"Kills\": [\"Deaths\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\"],\n",
        "    \"Deaths\": [\"Kills\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\"],\n",
        "    \"Assists\": [\"Kills\", \"Deaths\", \"KD\", \"KDA\", \"DF\", \"DR\"]\n",
        "}\n",
        "\n",
        "# Guardar resultados\n",
        "resultados = []\n",
        "\n",
        "for alvo in [\"Kills\", \"Deaths\", \"Assists\"]:\n",
        "    X = df[entradas_por_alvo[alvo]]\n",
        "    y = df[alvo]\n",
        "\n",
        "    # Normalizar\n",
        "    scaler_X = StandardScaler()\n",
        "    scaler_y = StandardScaler()\n",
        "    X_scaled = scaler_X.fit_transform(X)\n",
        "    y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # K-Fold CV\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    mae_scores = []\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X_scaled):\n",
        "        X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "        y_train, y_test = y_scaled[train_index], y_scaled[test_index]\n",
        "\n",
        "        modelo = SVR()\n",
        "        modelo.fit(X_train, y_train)\n",
        "        y_pred = modelo.predict(X_test)\n",
        "\n",
        "        # Desnormalizar\n",
        "        y_pred_inv = scaler_y.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
        "        y_test_inv = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "        mae_scores.append(mean_absolute_error(y_test_inv, y_pred_inv))\n",
        "        rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
        "        rmse_scores.append(rmse)\n",
        "\n",
        "    resultados.append({\n",
        "        \"Variável\": alvo,\n",
        "        \"MAE Médio\": np.mean(mae_scores),\n",
        "        \"RMSE Médio\": np.mean(rmse_scores)\n",
        "    })\n",
        "\n",
        "# Mostrar resultados\n",
        "df_resultados = pd.DataFrame(resultados)\n",
        "print(df_resultados)"
      ],
      "metadata": {
        "id": "4XSC5BC6SFVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVG"
      ],
      "metadata": {
        "id": "kY6IcXxX9slN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Carregar o dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Databases/win_lose_filtered.csv\")\n",
        "\n",
        "# Definir X e y\n",
        "X = df[[\"Kills\", \"Deaths\", \"Assists\", \"KD\", \"KDA\", \"DF\", \"DR\"]]\n",
        "y = df[\"Team Win\"]\n",
        "\n",
        "# Normalizar X (SVM precisa de dados escalados)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Inicializar o modelo SVM\n",
        "modelo = SVC(kernel=\"rbf\", random_state=42)\n",
        "\n",
        "# K-Fold\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "f1_scores = []\n",
        "\n",
        "# Rodar validação cruzada\n",
        "for train_idx, test_idx in kf.split(X_scaled):\n",
        "    X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "    precision_scores.append(precision_score(y_test, y_pred))\n",
        "    recall_scores.append(recall_score(y_test, y_pred))\n",
        "    f1_scores.append(f1_score(y_test, y_pred))\n",
        "\n",
        "# Exibir resultados como tabela\n",
        "df_resultados = pd.DataFrame({\n",
        "    \"Métrica\": [\"Acurácia\", \"Precision\", \"Recall\", \"F1-Score\"],\n",
        "    \"Valor Médio\": [\n",
        "        np.mean(accuracy_scores),\n",
        "        np.mean(precision_scores),\n",
        "        np.mean(recall_scores),\n",
        "        np.mean(f1_scores)\n",
        "    ]\n",
        "})\n",
        "print(df_resultados)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8WjZPjkR9slN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}